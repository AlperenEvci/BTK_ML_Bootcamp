{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boyut Azaltma\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#sklearn iris veri seti\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "#iris veri setini yükle\n",
    "iris = load_iris()\n",
    "\n",
    "data = iris.data\n",
    "feature_names = iris.feature_names\n",
    "y = iris.target\n",
    "\n",
    "#dataframe oluştur\n",
    "df = pd.DataFrame(data, columns=feature_names)\n",
    "df[\"Class\"] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temel Bileşen Analizi (PCA) ile boyut azaltma \n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2, whiten=True) #whiten=True veri setini normalize eder\n",
    "\n",
    "x_pca = pca.fit_transform(data)\n",
    "\n",
    "print(\"Varience Ratio: \", pca.explained_variance_ratio_)\n",
    "print(\"Sum: \", sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temel bileşenleri görselleştir\n",
    "\n",
    "df[\"p1\"] = x_pca[:,0]  #1 boyutlu hale getirildi\n",
    "df[\"p2\"] = x_pca[:,1]  #2 boyutlu hale getirildi\n",
    "\n",
    "color = [\"red\", \"green\", \"blue\"]\n",
    "\n",
    "for each in range(3):\n",
    "    plt.scatter(df.p1[df.Class == each], df.p2[df.Class == each], color=color[each], label=iris.target_names[each]) #sınıflara göre renklendir\n",
    "\n",
    "plt.xlabel(\"p1\")\n",
    "plt.ylabel(\"p2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eğer data çok karışık ise datayı kernel pca ile boyut azaltma yapabiliriz\n",
    "#kernel pca\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X ,y = make_circles(n_samples=1_000, random_state=0, noise=0.05, factor=0.3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42) #veri setini train ve test olarak ayır\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_, (train_ax, test_ax) = plt.subplots(ncols=2 ,sharex=True, sharey=True, figsize=(8, 4))\n",
    "\n",
    "train_ax.scatter(X_train[:,0],X_train[:,1], c=y_train)\n",
    "train_ax.set_xlabel('X1')\n",
    "train_ax.set_ylabel('X2')\n",
    "train_ax.set_title('Train Set')\n",
    "\n",
    "test_ax.scatter(X_test[:,0],X_test[:,1], c=y_test)\n",
    "test_ax.set_xlabel('X1')\n",
    "_ = test_ax.set_title('Test Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "pca = PCA(n_components=2) #normal pca\n",
    "kpca = KernelPCA(n_components=None, kernel='rbf',fit_inverse_transform=True, gamma=10 ,alpha=0.1)   #kernel pca \n",
    "\n",
    "X_test_pca = pca.fit_transform(X_train, X_test)\n",
    "X_test_kpca = kpca.fit_transform(X_train, X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (orig_ax, pca_ax, kpca_ax) = plt.subplots(ncols=3, figsize=(14, 4))\n",
    "\n",
    "# scatter plot with consistent 'c' argument\n",
    "orig_ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test[:len(X_test)], s=50, cmap='viridis', alpha=0.5)  # Fix: Use y_test[:len(X_test)] to match the size of X_test\n",
    "orig_ax.set_ylabel('öznitelik 1')\n",
    "orig_ax.set_xlabel('öznitelik 2')\n",
    "orig_ax.set_title('Original Data')\n",
    "\n",
    "pca_ax.scatter(X_test_pca[:, 0], X_test_pca[:, 1], c=y_test[:len(X_test_pca)], s=50)  # Fix: Use y_test[:len(X_test_pca)] to match the size of X_test_pca\n",
    "pca_ax.set_xlabel('1. bileşen')\n",
    "pca_ax.set_ylabel('2. bileşen')\n",
    "pca_ax.set_title('PCA')\n",
    "\n",
    "kpca_ax.scatter(X_test_kpca[:, 0], X_test_kpca[:, 1], c=y_test[:len(X_test_kpca)], s=50)  # Fix: Use y_test[:len(X_test_kpca)] to match the size of X_test_kpca\n",
    "kpca_ax.set_xlabel('1. bileşen')\n",
    "kpca_ax.set_ylabel('2. bileşen')\n",
    "kpca_ax.set_title('Kernel PCA')\n",
    "kpca_ax.set_ylabel('2. bileşen')\n",
    "_ = kpca_ax.set_title('Kernel PCA')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#varyans temelli öznitelik seçimi\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "X = [[0,0,1], [0,1,0], [1,0,0], [0,1,1], [0,1,0], [0,1,1]]\n",
    "\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8))) #varyansı 0.8 den büyük olanları seç \n",
    "sel.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #istatiksel model seçimi\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = SelectKBest(chi2, k=2).fit_transform(X, y)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #model tabanlı öznitelik seçimi\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alper\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#l1 tabanlı öznitelik seçimi\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X, y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#l2 tabanlı öznitelik seçimi\n",
    "lsvs = LinearSVC(C=0.01, penalty=\"l2\", dual=False).fit(X, y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ağaç tabanlı öznitelik seçimi\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    " \n",
    "X, y = load_iris(return_X_y=True)\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09279821, 0.07315838, 0.39366687, 0.44037654])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=50)\n",
    "clf = clf.fit(X, y)\n",
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "X_new.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
